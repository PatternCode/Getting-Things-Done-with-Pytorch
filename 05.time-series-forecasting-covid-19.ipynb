{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0LdAvhCnCMDL"
   },
   "source": [
    "# Time Series Forecasting with LSTMs for Daily Coronavirus Cases using PyTorch in Python "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A59PQFTSCQUg"
   },
   "source": [
    "> This tutorial is NOT trying to build a model that predicts the Covid-19 outbreak/pandemic in the best way possible. This is an example of how you can use Recurrent Neural Networks on some real-world Time Series data with PyTorch. Hopefully, there are much better models that predict the number of daily confirmed cases.\n",
    "\n",
    "Time series data captures a series of data points recorded at (usually) regular intervals. Some common examples include daily weather temperature, stock prices, and the number of sales a company makes.\n",
    "\n",
    "Many classical methods (e.g. ARIMA) try to deal with Time Series data with varying success (not to say they are bad at it). In the last couple of years, [Long Short Term Memory Networks (LSTM)](https://en.wikipedia.org/wiki/Long_short-term_memory) models have become a very useful method when dealing with those types of data.\n",
    "\n",
    "Recurrent Neural Networks (LSTMs are one type of those) are very good at processing sequences of data. They can \"recall\" patterns in the data that are very far into the past (or future). In this tutorial, you're going to learn how to use LSTMs to predict future Coronavirus cases based on real-world data.\n",
    "\n",
    "- [Run the complete notebook in your browser (Google Colab)](https://colab.research.google.com/drive/1nQYJq1f7f4R0yeZOzQ9rBKgk00AfLoS0)\n",
    "- [Read the Getting Things Done with Pytorch book](https://github.com/curiousily/Getting-Things-Done-with-Pytorch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IR387vTYWH68"
   },
   "source": [
    "## Novel Coronavirus (COVID-19)\n",
    "\n",
    "The novel Coronavirus (Covid-19) has spread around the world very rapidly. At the time of this writing, [Worldometers.info](https://www.worldometers.info/coronavirus/) shows that there are more than *95,488* confirmed cases in more than *84* countries.\n",
    "\n",
    "The top 4 worst-affected (by far) are China (the source of the virus), South Korea, Italy, and Iran. Unfortunately, many cases are currently not reported due to:\n",
    "\n",
    "- A person can get infected without even knowing (asymptomatic)\n",
    "- Incorrect data reporting\n",
    "- Not enough test kits\n",
    "- The symptoms look a lot like the common flu\n",
    "\n",
    "### How dangerous is this virus?\n",
    "\n",
    "Except for the common statistics you might see cited on the news, there are some good and some bad news:\n",
    "\n",
    "- More than 80% of the confirmed cases recover without any need of medical attention\n",
    "- [3.4% Mortality Rate estimate by the World Health Organization (WHO) as of March 3](https://www.worldometers.info/coronavirus/coronavirus-death-rate/#who-03-03-20)\n",
    "- The reproductive number which represents the average number of people to which a single infected person will transmit the virus is between 1.4 and 2.5 [(WHO's estimated on Jan. 23)](https://www.worldometers.info/coronavirus/#repro)\n",
    "\n",
    "The last one is really scary. It sounds like we can witness some crazy exponential growth if appropriate measures are not put in place.\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W8UyCsI_mlqP"
   },
   "outputs": [],
   "source": [
    "!pip install -Uq watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 125
    },
    "colab_type": "code",
    "id": "zI0W-_9XmjY6",
    "outputId": "774c547b-02d3-487c-88d7-d74620add20a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python implementation: CPython\n",
      "Python version       : 3.8.19\n",
      "IPython version      : 8.12.2\n",
      "\n",
      "numpy : 1.24.3\n",
      "pandas: 2.0.3\n",
      "torch : 2.3.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%reload_ext watermark\n",
    "%watermark -v -p numpy,pandas,torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "tzMzcTdKygBE",
    "outputId": "7f84d0cf-a465-4f36-9805-2f5619391df9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x19bf32dbb70>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "from torch import nn, optim\n",
    "\n",
    "# %matplotlib inline\n",
    "%matplotlib qt\n",
    "\n",
    "\n",
    "%config InlineBackend.figure_format='retina'\n",
    "\n",
    "sns.set(style='whitegrid', palette='muted', font_scale=1.2)\n",
    "\n",
    "HAPPY_COLORS_PALETTE = [\"#01BEFE\", \"#FFDD00\", \"#FF7D00\", \"#FF006D\", \"#93D30C\", \"#8F00FF\"]\n",
    "\n",
    "sns.set_palette(sns.color_palette(HAPPY_COLORS_PALETTE))\n",
    "\n",
    "rcParams['figure.figsize'] = 14, 10\n",
    "register_matplotlib_converters()\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2Jmoo1E2XM4y"
   },
   "source": [
    "## Daily Cases Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jz_3S--lXK9a"
   },
   "source": [
    "The data is provided by the Johns Hopkins University Center for Systems Science and Engineering (JHU CSSE) and contains the number of reported daily cases by country. [The dataset is available on GitHub](https://github.com/CSSEGISandData/COVID-19) and is updated regularly.\n",
    "\n",
    "We're going to take the Time Series data only for confirmed cases (number of deaths and recovered cases are also available):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qspvxWyoypeX"
   },
   "outputs": [],
   "source": [
    "# !wget https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_19-covid-Confirmed.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F1L-crLVYq-s"
   },
   "source": [
    "Or you can take the same dataset that I've used for this tutorial (the data snapshot is from 3 March 2020):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "colab_type": "code",
    "id": "ISbbDUFl8SvH",
    "outputId": "052a3e38-ebde-42a2-b8c2-ffd565504bf3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ehsan.Namjoo\\AppData\\Local\\miniconda3\\envs\\pytorch_env\\lib\\site-packages\\gdown\\__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
      "  warnings.warn(\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1AsfdLrGESCQnRW5rbMz56A1KBc3Fe5aV\n",
      "To: D:\\Repository\\Getting-Things-Done-with-Pytorch\\time_series_19-covid-Confirmed.csv\n",
      "\n",
      "  0%|          | 0.00/19.2k [00:00<?, ?B/s]\n",
      "100%|##########| 19.2k/19.2k [00:00<?, ?B/s]\n"
     ]
    }
   ],
   "source": [
    "!gdown --id 1AsfdLrGESCQnRW5rbMz56A1KBc3Fe5aV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L9GCMpR58kxd"
   },
   "source": [
    "## Data exploration\n",
    "\n",
    "Let's load the data and have a peek:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "colab_type": "code",
    "id": "3_15jwwrASTP",
    "outputId": "beb76603-82b3-435c-a01c-0c7c0175e8c8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Province/State</th>\n",
       "      <th>Country/Region</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long</th>\n",
       "      <th>1/22/20</th>\n",
       "      <th>1/23/20</th>\n",
       "      <th>1/24/20</th>\n",
       "      <th>1/25/20</th>\n",
       "      <th>1/26/20</th>\n",
       "      <th>1/27/20</th>\n",
       "      <th>...</th>\n",
       "      <th>2/22/20</th>\n",
       "      <th>2/23/20</th>\n",
       "      <th>2/24/20</th>\n",
       "      <th>2/25/20</th>\n",
       "      <th>2/26/20</th>\n",
       "      <th>2/27/20</th>\n",
       "      <th>2/28/20</th>\n",
       "      <th>2/29/20</th>\n",
       "      <th>3/1/20</th>\n",
       "      <th>3/2/20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anhui</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>31.8257</td>\n",
       "      <td>117.2264</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "      <td>39</td>\n",
       "      <td>60</td>\n",
       "      <td>70</td>\n",
       "      <td>...</td>\n",
       "      <td>989</td>\n",
       "      <td>989</td>\n",
       "      <td>989</td>\n",
       "      <td>989</td>\n",
       "      <td>989</td>\n",
       "      <td>989</td>\n",
       "      <td>990</td>\n",
       "      <td>990</td>\n",
       "      <td>990</td>\n",
       "      <td>990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Beijing</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>40.1824</td>\n",
       "      <td>116.4142</td>\n",
       "      <td>14</td>\n",
       "      <td>22</td>\n",
       "      <td>36</td>\n",
       "      <td>41</td>\n",
       "      <td>68</td>\n",
       "      <td>80</td>\n",
       "      <td>...</td>\n",
       "      <td>399</td>\n",
       "      <td>399</td>\n",
       "      <td>399</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>410</td>\n",
       "      <td>410</td>\n",
       "      <td>411</td>\n",
       "      <td>413</td>\n",
       "      <td>414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chongqing</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>30.0572</td>\n",
       "      <td>107.8740</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>27</td>\n",
       "      <td>57</td>\n",
       "      <td>75</td>\n",
       "      <td>110</td>\n",
       "      <td>...</td>\n",
       "      <td>573</td>\n",
       "      <td>575</td>\n",
       "      <td>576</td>\n",
       "      <td>576</td>\n",
       "      <td>576</td>\n",
       "      <td>576</td>\n",
       "      <td>576</td>\n",
       "      <td>576</td>\n",
       "      <td>576</td>\n",
       "      <td>576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fujian</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>26.0789</td>\n",
       "      <td>117.9874</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>18</td>\n",
       "      <td>35</td>\n",
       "      <td>59</td>\n",
       "      <td>...</td>\n",
       "      <td>293</td>\n",
       "      <td>293</td>\n",
       "      <td>293</td>\n",
       "      <td>294</td>\n",
       "      <td>294</td>\n",
       "      <td>296</td>\n",
       "      <td>296</td>\n",
       "      <td>296</td>\n",
       "      <td>296</td>\n",
       "      <td>296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gansu</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>36.0611</td>\n",
       "      <td>103.8343</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>91</td>\n",
       "      <td>91</td>\n",
       "      <td>91</td>\n",
       "      <td>91</td>\n",
       "      <td>91</td>\n",
       "      <td>91</td>\n",
       "      <td>91</td>\n",
       "      <td>91</td>\n",
       "      <td>91</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>Placer County, CA</td>\n",
       "      <td>US</td>\n",
       "      <td>39.0916</td>\n",
       "      <td>-120.8039</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>San Mateo, CA</td>\n",
       "      <td>US</td>\n",
       "      <td>37.5630</td>\n",
       "      <td>-122.3255</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>Sarasota, FL</td>\n",
       "      <td>US</td>\n",
       "      <td>27.3364</td>\n",
       "      <td>-82.5307</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>Sonoma County, CA</td>\n",
       "      <td>US</td>\n",
       "      <td>38.5780</td>\n",
       "      <td>-122.9888</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>Umatilla, OR</td>\n",
       "      <td>US</td>\n",
       "      <td>45.7750</td>\n",
       "      <td>-118.7606</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>142 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Province/State  Country/Region      Lat      Long  1/22/20  1/23/20  \\\n",
       "0                Anhui  Mainland China  31.8257  117.2264        1        9   \n",
       "1              Beijing  Mainland China  40.1824  116.4142       14       22   \n",
       "2            Chongqing  Mainland China  30.0572  107.8740        6        9   \n",
       "3               Fujian  Mainland China  26.0789  117.9874        1        5   \n",
       "4                Gansu  Mainland China  36.0611  103.8343        0        2   \n",
       "..                 ...             ...      ...       ...      ...      ...   \n",
       "137  Placer County, CA              US  39.0916 -120.8039        0        0   \n",
       "138      San Mateo, CA              US  37.5630 -122.3255        0        0   \n",
       "139       Sarasota, FL              US  27.3364  -82.5307        0        0   \n",
       "140  Sonoma County, CA              US  38.5780 -122.9888        0        0   \n",
       "141       Umatilla, OR              US  45.7750 -118.7606        0        0   \n",
       "\n",
       "     1/24/20  1/25/20  1/26/20  1/27/20  ...  2/22/20  2/23/20  2/24/20  \\\n",
       "0         15       39       60       70  ...      989      989      989   \n",
       "1         36       41       68       80  ...      399      399      399   \n",
       "2         27       57       75      110  ...      573      575      576   \n",
       "3         10       18       35       59  ...      293      293      293   \n",
       "4          2        4        7       14  ...       91       91       91   \n",
       "..       ...      ...      ...      ...  ...      ...      ...      ...   \n",
       "137        0        0        0        0  ...        0        0        0   \n",
       "138        0        0        0        0  ...        0        0        0   \n",
       "139        0        0        0        0  ...        0        0        0   \n",
       "140        0        0        0        0  ...        0        0        0   \n",
       "141        0        0        0        0  ...        0        0        0   \n",
       "\n",
       "     2/25/20  2/26/20  2/27/20  2/28/20  2/29/20  3/1/20  3/2/20  \n",
       "0        989      989      989      990      990     990     990  \n",
       "1        400      400      410      410      411     413     414  \n",
       "2        576      576      576      576      576     576     576  \n",
       "3        294      294      296      296      296     296     296  \n",
       "4         91       91       91       91       91      91      91  \n",
       "..       ...      ...      ...      ...      ...     ...     ...  \n",
       "137        0        0        0        0        0       0       1  \n",
       "138        0        0        0        0        0       0       1  \n",
       "139        0        0        0        0        0       0       1  \n",
       "140        0        0        0        0        0       0       1  \n",
       "141        0        0        0        0        0       0       1  \n",
       "\n",
       "[142 rows x 45 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('time_series_19-covid-Confirmed.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(142, 45)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "639__gtacb-5"
   },
   "source": [
    "Two things to note here:\n",
    "\n",
    "- The data contains a province, country, latitude, and longitude. We won't be needing those.\n",
    "- The number of cases is cumulative. We'll undo the accumulation.\n",
    "\n",
    "Let's start by getting rid of the first four columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lx2bxxJyWLdU"
   },
   "outputs": [],
   "source": [
    "df = df.iloc[:, 4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "colab_type": "code",
    "id": "zYREMR00ZeUT",
    "outputId": "e291eb25-5800-4b74-dec4-63c193898fdf"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1/22/20</th>\n",
       "      <th>1/23/20</th>\n",
       "      <th>1/24/20</th>\n",
       "      <th>1/25/20</th>\n",
       "      <th>1/26/20</th>\n",
       "      <th>1/27/20</th>\n",
       "      <th>1/28/20</th>\n",
       "      <th>1/29/20</th>\n",
       "      <th>1/30/20</th>\n",
       "      <th>1/31/20</th>\n",
       "      <th>...</th>\n",
       "      <th>2/22/20</th>\n",
       "      <th>2/23/20</th>\n",
       "      <th>2/24/20</th>\n",
       "      <th>2/25/20</th>\n",
       "      <th>2/26/20</th>\n",
       "      <th>2/27/20</th>\n",
       "      <th>2/28/20</th>\n",
       "      <th>2/29/20</th>\n",
       "      <th>3/1/20</th>\n",
       "      <th>3/2/20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "      <td>39</td>\n",
       "      <td>60</td>\n",
       "      <td>70</td>\n",
       "      <td>106</td>\n",
       "      <td>152</td>\n",
       "      <td>200</td>\n",
       "      <td>237</td>\n",
       "      <td>...</td>\n",
       "      <td>989</td>\n",
       "      <td>989</td>\n",
       "      <td>989</td>\n",
       "      <td>989</td>\n",
       "      <td>989</td>\n",
       "      <td>989</td>\n",
       "      <td>990</td>\n",
       "      <td>990</td>\n",
       "      <td>990</td>\n",
       "      <td>990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14</td>\n",
       "      <td>22</td>\n",
       "      <td>36</td>\n",
       "      <td>41</td>\n",
       "      <td>68</td>\n",
       "      <td>80</td>\n",
       "      <td>91</td>\n",
       "      <td>111</td>\n",
       "      <td>114</td>\n",
       "      <td>139</td>\n",
       "      <td>...</td>\n",
       "      <td>399</td>\n",
       "      <td>399</td>\n",
       "      <td>399</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>410</td>\n",
       "      <td>410</td>\n",
       "      <td>411</td>\n",
       "      <td>413</td>\n",
       "      <td>414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>27</td>\n",
       "      <td>57</td>\n",
       "      <td>75</td>\n",
       "      <td>110</td>\n",
       "      <td>132</td>\n",
       "      <td>147</td>\n",
       "      <td>182</td>\n",
       "      <td>211</td>\n",
       "      <td>...</td>\n",
       "      <td>573</td>\n",
       "      <td>575</td>\n",
       "      <td>576</td>\n",
       "      <td>576</td>\n",
       "      <td>576</td>\n",
       "      <td>576</td>\n",
       "      <td>576</td>\n",
       "      <td>576</td>\n",
       "      <td>576</td>\n",
       "      <td>576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>18</td>\n",
       "      <td>35</td>\n",
       "      <td>59</td>\n",
       "      <td>80</td>\n",
       "      <td>84</td>\n",
       "      <td>101</td>\n",
       "      <td>120</td>\n",
       "      <td>...</td>\n",
       "      <td>293</td>\n",
       "      <td>293</td>\n",
       "      <td>293</td>\n",
       "      <td>294</td>\n",
       "      <td>294</td>\n",
       "      <td>296</td>\n",
       "      <td>296</td>\n",
       "      <td>296</td>\n",
       "      <td>296</td>\n",
       "      <td>296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>19</td>\n",
       "      <td>24</td>\n",
       "      <td>26</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>91</td>\n",
       "      <td>91</td>\n",
       "      <td>91</td>\n",
       "      <td>91</td>\n",
       "      <td>91</td>\n",
       "      <td>91</td>\n",
       "      <td>91</td>\n",
       "      <td>91</td>\n",
       "      <td>91</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   1/22/20  1/23/20  1/24/20  1/25/20  1/26/20  1/27/20  1/28/20  1/29/20  \\\n",
       "0        1        9       15       39       60       70      106      152   \n",
       "1       14       22       36       41       68       80       91      111   \n",
       "2        6        9       27       57       75      110      132      147   \n",
       "3        1        5       10       18       35       59       80       84   \n",
       "4        0        2        2        4        7       14       19       24   \n",
       "\n",
       "   1/30/20  1/31/20  ...  2/22/20  2/23/20  2/24/20  2/25/20  2/26/20  \\\n",
       "0      200      237  ...      989      989      989      989      989   \n",
       "1      114      139  ...      399      399      399      400      400   \n",
       "2      182      211  ...      573      575      576      576      576   \n",
       "3      101      120  ...      293      293      293      294      294   \n",
       "4       26       29  ...       91       91       91       91       91   \n",
       "\n",
       "   2/27/20  2/28/20  2/29/20  3/1/20  3/2/20  \n",
       "0      989      990      990     990     990  \n",
       "1      410      410      411     413     414  \n",
       "2      576      576      576     576     576  \n",
       "3      296      296      296     296     296  \n",
       "4       91       91       91      91      91  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hdBlnURyXVgw"
   },
   "source": [
    "Let's check for missing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "8yb8Ov_Ia5Se",
    "outputId": "5ea6a354-d60a-460b-eb33-df4bd7468ffa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hqolOGG3cZcT"
   },
   "source": [
    "Everything seems to be in place. Let's sum all rows, so we get the cumulative daily cases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_cases = df.sum(axis=0)\n",
    "daily_cases.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 125
    },
    "colab_type": "code",
    "id": "DbVKPyMybITz",
    "outputId": "e84a4ba5-d34c-4f65-eb92-467ba28c3104"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ehsan.Namjoo\\AppData\\Local\\Temp\\ipykernel_16668\\2322952749.py:1: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  daily_cases.index = pd.to_datetime(daily_cases.index)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2020-01-22     555\n",
       "2020-01-23     653\n",
       "2020-01-24     941\n",
       "2020-01-25    1434\n",
       "2020-01-26    2118\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_cases.index = pd.to_datetime(daily_cases.index)\n",
    "# daily_cases.index = pd.to_datetime(daily_cases.index) converts the index of a Pandas DataFrame \n",
    "# called daily_cases from a string representation of dates and times to actual datetime objects.\n",
    "# This allows you to perform time-based operations more easily. For example, you can calculate\n",
    "# time differences or resample data based on specific time intervals\n",
    "daily_cases.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 614
    },
    "colab_type": "code",
    "id": "QyTmkP2OQLui",
    "outputId": "3c70298c-36ba-448d-e551-4759d3a277ea"
   },
   "outputs": [],
   "source": [
    "plt.plot(daily_cases)\n",
    "plt.title(\"Cumulative daily cases\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K4VmZuoyeAiZ"
   },
   "source": [
    "We'll undo the accumulation by subtracting the current value from the previous. We'll preserve the first value of the sequence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 125
    },
    "colab_type": "code",
    "id": "Lb-6wPBYb1uG",
    "outputId": "4079bbfe-5381-430e-9834-b0c2b76235d0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2020-01-22    555\n",
       "2020-01-23     98\n",
       "2020-01-24    288\n",
       "2020-01-25    493\n",
       "2020-01-26    684\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_cases = daily_cases.diff().fillna(daily_cases[0]).astype(np.int64)\n",
    "daily_cases.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 614
    },
    "colab_type": "code",
    "id": "KVXZ7tCsQvHX",
    "outputId": "160b929f-7c9f-4b68-bdc6-eed2565ed283"
   },
   "outputs": [],
   "source": [
    "plt.plot(daily_cases)\n",
    "plt.title(\"Daily cases\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_KX1spUAgIcy"
   },
   "source": [
    "The huge spike (in the middle) is mostly due to a change of criteria for testing patients in China. This will certainly be a challenge for our model.\n",
    "\n",
    "Let's check the amount of data we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "Ij7GhQKsN094",
    "outputId": "7a4ed8bc-617d-434d-e8a7-4d1fe57d61f1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_cases.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qjFl0n8oki8I"
   },
   "source": [
    "Unfortunately, we have data for only 41 days. Let's see what we can do with it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T4ONc718zaAW"
   },
   "source": [
    "## Preprocessing\n",
    "\n",
    "We'll reserve the first 27 days for training and use the rest for testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "4xsvSUYFRwkk",
    "outputId": "f606dd42-97be-4b8b-f8da-ef1700a42361"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27, 1)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_size = 14\n",
    "\n",
    "train_data = daily_cases[:-test_data_size] # take all elements of daily_cases except the last 14\n",
    "test_data = daily_cases[-test_data_size:] # will contain all elements from the beginning of daily_cases\n",
    "                                          # up to, but not including, the last 14 elements\n",
    "\n",
    "train_data.shape\n",
    "np.expand_dims(train_data, axis=1).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i8SRrEWSZujN"
   },
   "source": [
    "We have to scale the data (values will be between 0 and 1) if we want to increase the training speed and performance of the model. We'll use the `MinMaxScaler` from scikit-learn:\n",
    "\n",
    "**Expected Input for Scaler**: The MinMaxScaler and most other scalers in scikit-learn expect the input data to be in a __2D array format__, where **each row** represents a **sample** and **each column** represents a feature. For **univariate data** (a single feature), this means the expected shape is **(n, 1)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZMKl_mSZUENB"
   },
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler() # The MinMaxScaler is used to normalize the data such that all values are within\n",
    "                        # a specified range (default is 0 to 1).\n",
    "\n",
    "scaler = scaler.fit(np.expand_dims(train_data, axis=1))\n",
    "#  np.expand_dims(train_data, axis=1) reshapes the train_data into a 2D array with one column. This is necessary\n",
    "# because MinMaxScaler expects 2D input (a matrix with rows and columns).\n",
    "# The fit method computes the minimum and maximum values of train_data to learn the parameters required for scaling.\n",
    "\n",
    "train_data = scaler.transform(np.expand_dims(train_data, axis=1))\n",
    "\n",
    "test_data = scaler.transform(np.expand_dims(test_data, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.03036545],\n",
       "       [0.        ],\n",
       "       [0.01262458],\n",
       "       [0.02624585],\n",
       "       [0.03893688],\n",
       "       [0.04724252],\n",
       "       [0.16963455],\n",
       "       [0.03255814],\n",
       "       [0.13089701],\n",
       "       [0.10598007],\n",
       "       [0.13375415],\n",
       "       [0.30903654],\n",
       "       [0.19906977],\n",
       "       [0.26      ],\n",
       "       [0.24225914],\n",
       "       [0.20491694],\n",
       "       [0.23096346],\n",
       "       [0.17481728],\n",
       "       [0.19481728],\n",
       "       [0.16704319],\n",
       "       [0.12903654],\n",
       "       [0.0213289 ],\n",
       "       [1.        ],\n",
       "       [0.42651163],\n",
       "       [0.13601329],\n",
       "       [0.1392691 ],\n",
       "       [0.12863787]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```np.expand_dims(test_data, axis=1)``` reshapes the ```test_data```  to ensure it is in the correct 2D format.\n",
    "**The transform method scales the test data using the same parameters (min and max values) learned from the training data**.\n",
    "This ensures that the scaling applied to the test data is consistent with the scaling applied to the training data.\n",
    "\n",
    "\n",
    "**Why This is Done**\n",
    "\n",
    "__Normalization__: Scaling data to a range (like 0 to 1) is a common preprocessing step in machine learning. It ensures that each feature contributes equally to the result and helps improve the convergence of gradient descent algorithms.\n",
    "\n",
    "__Consistency__: Fitting the scaler only on the training data and then applying it to both the training and test data ensures that the test data is scaled using the same parameters as the training data. This prevents data leakage and ensures the model's performance is evaluated correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-KD-OgmQbdac"
   },
   "source": [
    "Currently, we have a big sequence of daily cases. We'll convert it into smaller ones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tN7P8h-uHSKV"
   },
   "outputs": [],
   "source": [
    "def create_sequences(data, seq_length):\n",
    "    xs = []\n",
    "    ys = []\n",
    "\n",
    "    for i in range(len(data)-seq_length-1):\n",
    "        x = data[i:(i+seq_length)]\n",
    "        y = data[i+seq_length]\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "\n",
    "    return np.array(xs), np.array(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "92DqpTj8IxDI"
   },
   "outputs": [],
   "source": [
    "seq_length = 5\n",
    "X_train, y_train = create_sequences(train_data, seq_length)\n",
    "X_test, y_test = create_sequences(test_data, seq_length)\n",
    "\n",
    "X_train = torch.from_numpy(X_train).float()\n",
    "y_train = torch.from_numpy(y_train).float()\n",
    "\n",
    "X_test = torch.from_numpy(X_test).float()\n",
    "y_test = torch.from_numpy(y_test).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EBN2MIinc2FN"
   },
   "source": [
    "Each training example contains a sequence of 5 data points of history and a label for the real value that our model needs to predict. Let's dive in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0304],\n",
       "         [0.0000],\n",
       "         [0.0126],\n",
       "         [0.0262],\n",
       "         [0.0389]],\n",
       "\n",
       "        [[0.0000],\n",
       "         [0.0126],\n",
       "         [0.0262],\n",
       "         [0.0389],\n",
       "         [0.0472]],\n",
       "\n",
       "        [[0.0126],\n",
       "         [0.0262],\n",
       "         [0.0389],\n",
       "         [0.0472],\n",
       "         [0.1696]],\n",
       "\n",
       "        [[0.0262],\n",
       "         [0.0389],\n",
       "         [0.0472],\n",
       "         [0.1696],\n",
       "         [0.0326]],\n",
       "\n",
       "        [[0.0389],\n",
       "         [0.0472],\n",
       "         [0.1696],\n",
       "         [0.0326],\n",
       "         [0.1309]],\n",
       "\n",
       "        [[0.0472],\n",
       "         [0.1696],\n",
       "         [0.0326],\n",
       "         [0.1309],\n",
       "         [0.1060]],\n",
       "\n",
       "        [[0.1696],\n",
       "         [0.0326],\n",
       "         [0.1309],\n",
       "         [0.1060],\n",
       "         [0.1338]],\n",
       "\n",
       "        [[0.0326],\n",
       "         [0.1309],\n",
       "         [0.1060],\n",
       "         [0.1338],\n",
       "         [0.3090]],\n",
       "\n",
       "        [[0.1309],\n",
       "         [0.1060],\n",
       "         [0.1338],\n",
       "         [0.3090],\n",
       "         [0.1991]],\n",
       "\n",
       "        [[0.1060],\n",
       "         [0.1338],\n",
       "         [0.3090],\n",
       "         [0.1991],\n",
       "         [0.2600]],\n",
       "\n",
       "        [[0.1338],\n",
       "         [0.3090],\n",
       "         [0.1991],\n",
       "         [0.2600],\n",
       "         [0.2423]],\n",
       "\n",
       "        [[0.3090],\n",
       "         [0.1991],\n",
       "         [0.2600],\n",
       "         [0.2423],\n",
       "         [0.2049]],\n",
       "\n",
       "        [[0.1991],\n",
       "         [0.2600],\n",
       "         [0.2423],\n",
       "         [0.2049],\n",
       "         [0.2310]],\n",
       "\n",
       "        [[0.2600],\n",
       "         [0.2423],\n",
       "         [0.2049],\n",
       "         [0.2310],\n",
       "         [0.1748]],\n",
       "\n",
       "        [[0.2423],\n",
       "         [0.2049],\n",
       "         [0.2310],\n",
       "         [0.1748],\n",
       "         [0.1948]],\n",
       "\n",
       "        [[0.2049],\n",
       "         [0.2310],\n",
       "         [0.1748],\n",
       "         [0.1948],\n",
       "         [0.1670]],\n",
       "\n",
       "        [[0.2310],\n",
       "         [0.1748],\n",
       "         [0.1948],\n",
       "         [0.1670],\n",
       "         [0.1290]],\n",
       "\n",
       "        [[0.1748],\n",
       "         [0.1948],\n",
       "         [0.1670],\n",
       "         [0.1290],\n",
       "         [0.0213]],\n",
       "\n",
       "        [[0.1948],\n",
       "         [0.1670],\n",
       "         [0.1290],\n",
       "         [0.0213],\n",
       "         [1.0000]],\n",
       "\n",
       "        [[0.1670],\n",
       "         [0.1290],\n",
       "         [0.0213],\n",
       "         [1.0000],\n",
       "         [0.4265]],\n",
       "\n",
       "        [[0.1290],\n",
       "         [0.0213],\n",
       "         [1.0000],\n",
       "         [0.4265],\n",
       "         [0.1360]]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "5Db7NMt1haaw",
    "outputId": "f3141da7-fd47-4692-df43-71f36a370674"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0191],\n",
       "        [0.0324],\n",
       "        [0.0496],\n",
       "        [0.0587],\n",
       "        [0.0838],\n",
       "        [0.0843],\n",
       "        [0.1191],\n",
       "        [0.1502]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 215
    },
    "colab_type": "code",
    "id": "nouTrj7Vhd3i",
    "outputId": "48602534-c809-4552-afc8-bc274170c325"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0304],\n",
       "         [0.0000],\n",
       "         [0.0126],\n",
       "         [0.0262],\n",
       "         [0.0389]],\n",
       "\n",
       "        [[0.0000],\n",
       "         [0.0126],\n",
       "         [0.0262],\n",
       "         [0.0389],\n",
       "         [0.0472]]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "eSi-I0L1hiDB",
    "outputId": "79e67bda-9868-47fa-afbe-e49f6d002784"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([21, 5, 1])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "-fDsqZD6hjF8",
    "outputId": "8084d8e7-45e3-4b58-ae2f-2676bd984fc0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([21, 1])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "egnpqcZwP59F"
   },
   "source": [
    "## Building a model\n",
    "\n",
    "We'll encapsulate the complexity of our model into a class that extends from `torch.nn.Module`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vS1uFo4-qVT2"
   },
   "outputs": [],
   "source": [
    "class CoronaVirusPredictor(nn.Module):\n",
    "\n",
    "  def __init__(self, n_features, n_hidden, seq_len, n_layers=2):\n",
    "    super(CoronaVirusPredictor, self).__init__()\n",
    "\n",
    "    self.n_hidden = n_hidden\n",
    "    self.seq_len = seq_len\n",
    "    self.n_layers = n_layers\n",
    "\n",
    "    self.lstm = nn.LSTM(\n",
    "      input_size=n_features,\n",
    "      hidden_size=n_hidden,\n",
    "      num_layers=n_layers,\n",
    "      dropout=0.5\n",
    "    )\n",
    "\n",
    "    self.linear = nn.Linear(in_features=n_hidden, out_features=1)\n",
    "\n",
    "  def reset_hidden_state(self):\n",
    "    self.hidden = (\n",
    "        torch.zeros(self.n_layers, self.seq_len, self.n_hidden),\n",
    "        torch.zeros(self.n_layers, self.seq_len, self.n_hidden)\n",
    "    )\n",
    "\n",
    "  def forward(self, sequences):\n",
    "    lstm_out, self.hidden = self.lstm(\n",
    "      sequences.view(len(sequences), self.seq_len, -1),\n",
    "      self.hidden\n",
    "    )\n",
    "    last_time_step = \\\n",
    "      lstm_out.view(self.seq_len, len(sequences), self.n_hidden)[-1]\n",
    "    y_pred = self.linear(last_time_step)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xljmrTGUfduG"
   },
   "source": [
    "Our `CoronaVirusPredictor` contains 3 methods:\n",
    "- constructor - initialize all helper data and create the layers\n",
    "- `reset_hidden_state` - we'll use a stateless LSTM, so we need to reset the state after each example\n",
    "- `forward` - get the sequences, pass all of them through the LSTM layer, at once. We take the output of the last time step and pass it through our linear layer to get the prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FuggK-kC9BMQ"
   },
   "source": [
    "## Training\n",
    "\n",
    "Let's build a helper function for the training of our model (we'll reuse it later):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vsuBhEJ1fLnM"
   },
   "outputs": [],
   "source": [
    "def train_model(\n",
    "  model, \n",
    "  train_data, \n",
    "  train_labels, \n",
    "  test_data=None, \n",
    "  test_labels=None\n",
    "):\n",
    "  loss_fn = torch.nn.MSELoss(reduction='sum')\n",
    "\n",
    "  optimiser = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "  num_epochs = 60\n",
    "\n",
    "  train_hist = np.zeros(num_epochs)\n",
    "  test_hist = np.zeros(num_epochs)\n",
    "\n",
    "  for t in range(num_epochs):\n",
    "    model.reset_hidden_state()\n",
    "\n",
    "    y_pred = model(X_train)\n",
    "\n",
    "    loss = loss_fn(y_pred.float(), y_train)\n",
    "\n",
    "    if test_data is not None:\n",
    "      with torch.no_grad():\n",
    "        y_test_pred = model(X_test)\n",
    "        test_loss = loss_fn(y_test_pred.float(), y_test)\n",
    "      test_hist[t] = test_loss.item()\n",
    "\n",
    "      if t % 10 == 0:  \n",
    "        print(f'Epoch {t} train loss: {loss.item()} test loss: {test_loss.item()}')\n",
    "    elif t % 10 == 0:\n",
    "      print(f'Epoch {t} train loss: {loss.item()}')\n",
    "\n",
    "    train_hist[t] = loss.item()\n",
    "    \n",
    "    optimiser.zero_grad()\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    optimiser.step()\n",
    "  \n",
    "  return model.eval(), train_hist, test_hist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tBWwvJ8umKyw"
   },
   "source": [
    "Note that the hidden state is reset at the start of each epoch. We don't use batches of data our model sees every example at once. We'll use mean squared error to measure our training and test error. We'll record both. \n",
    "\n",
    "Let's create an instance of our model and train it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 125
    },
    "colab_type": "code",
    "id": "6f_ebtcBqaoK",
    "outputId": "4dfba810-b81c-498b-8426-85ba9a33f2c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 train loss: 1.6297187805175781 test loss: 0.0411866158246994\n",
      "Epoch 10 train loss: 0.8466923832893372 test loss: 0.12416429072618484\n",
      "Epoch 20 train loss: 0.8219935297966003 test loss: 0.1438201367855072\n",
      "Epoch 30 train loss: 0.8200692534446716 test loss: 0.2190694659948349\n",
      "Epoch 40 train loss: 0.810839056968689 test loss: 0.17977145314216614\n",
      "Epoch 50 train loss: 0.7957305312156677 test loss: 0.19855858385562897\n"
     ]
    }
   ],
   "source": [
    "model = CoronaVirusPredictor(\n",
    "  n_features=1, \n",
    "  n_hidden=512, \n",
    "  seq_len=seq_length, \n",
    "  n_layers=2\n",
    ")\n",
    "model, train_hist, test_hist = train_model(\n",
    "  model, \n",
    "  X_train, \n",
    "  y_train, \n",
    "  X_test, \n",
    "  y_test\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cL-9E4wLmnzR"
   },
   "source": [
    "Let's have a look at the train and test loss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 602
    },
    "colab_type": "code",
    "id": "gkqy6CNh9AqC",
    "outputId": "657e3154-4059-4bfc-d4f3-169714f1fe43"
   },
   "outputs": [],
   "source": [
    "plt.plot(train_hist, label=\"Training loss\")\n",
    "plt.plot(test_hist, label=\"Test loss\")\n",
    "plt.ylim((0, 5))\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_pKZ7Js8m60H"
   },
   "source": [
    "Our model's performance doesn't improve after 15 epochs or so. Recall that we have very little data. Maybe we shouldn't trust our model that much?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Weyp3LRBGEvv"
   },
   "source": [
    "## Predicting daily cases\n",
    "\n",
    "Our model can (due to the way we've trained it) predict only a single day in the future. We'll employ a simple strategy to overcome this limitation. Use predicted values as input for predicting the next days:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6RTIMgBZ_hG_"
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "  test_seq = X_test[:1]\n",
    "  preds = []\n",
    "  for _ in range(len(X_test)):\n",
    "    y_test_pred = model(test_seq)\n",
    "    pred = torch.flatten(y_test_pred).item()\n",
    "    preds.append(pred)\n",
    "    new_seq = test_seq.numpy().flatten()\n",
    "    new_seq = np.append(new_seq, [pred])\n",
    "    new_seq = new_seq[1:]\n",
    "    test_seq = torch.as_tensor(new_seq).view(1, seq_length, 1).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YBn9VijrubKS"
   },
   "source": [
    "We have to reverse the scaling of the test data and the model predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iPJMdlBEErg3"
   },
   "outputs": [],
   "source": [
    "true_cases = scaler.inverse_transform(\n",
    "    np.expand_dims(y_test.flatten().numpy(), axis=0)\n",
    ").flatten()\n",
    "\n",
    "predicted_cases = scaler.inverse_transform(\n",
    "  np.expand_dims(preds, axis=0)\n",
    ").flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bIaUwP2gue1I"
   },
   "source": [
    "Let's look at the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 597
    },
    "colab_type": "code",
    "id": "L_2LezBrE8VF",
    "outputId": "50b2de93-3f79-46a5-a9f0-f82545dda382"
   },
   "outputs": [],
   "source": [
    "plt.plot(\n",
    "  daily_cases.index[:len(train_data)], \n",
    "  scaler.inverse_transform(train_data).flatten(),\n",
    "  label='Historical Daily Cases'\n",
    ")\n",
    "\n",
    "plt.plot(\n",
    "  daily_cases.index[len(train_data):len(train_data) + len(true_cases)], \n",
    "  true_cases,\n",
    "  label='Real Daily Cases'\n",
    ")\n",
    "\n",
    "plt.plot(\n",
    "  daily_cases.index[len(train_data):len(train_data) + len(true_cases)], \n",
    "  predicted_cases, \n",
    "  label='Predicted Daily Cases'\n",
    ")\n",
    "\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dVXs97Onu9VV"
   },
   "source": [
    "As expected, our model doesn't perform very well. That said, the predictions seem to be in the right ballpark (probably due to using the last data point as a strong predictor for the next)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cmX5Cq_aGA2s"
   },
   "source": [
    "## Use all data for training\n",
    "\n",
    "Now, we'll use all available data to train the same model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "WbKlhXMuGhco",
    "outputId": "cffae6d3-a929-4c95-edb5-970c5f141a97"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41, 1)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "\n",
    "scaler = scaler.fit(np.expand_dims(daily_cases, axis=1))\n",
    "\n",
    "all_data = scaler.transform(np.expand_dims(daily_cases, axis=1))\n",
    "\n",
    "all_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9QzF2RC4YIA6"
   },
   "source": [
    "The preprocessing and training steps are the same:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 125
    },
    "colab_type": "code",
    "id": "toqibTKDGzzm",
    "outputId": "773ac4f1-63f9-4598-953b-74012b1d206f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 train loss: 1.9441421031951904\n",
      "Epoch 10 train loss: 0.8385428190231323\n",
      "Epoch 20 train loss: 0.8256546854972839\n",
      "Epoch 30 train loss: 0.8023681044578552\n",
      "Epoch 40 train loss: 0.8125611543655396\n",
      "Epoch 50 train loss: 0.8225002884864807\n"
     ]
    }
   ],
   "source": [
    "X_all, y_all = create_sequences(all_data, seq_length)\n",
    "\n",
    "X_all = torch.from_numpy(X_all).float()\n",
    "y_all = torch.from_numpy(y_all).float()\n",
    "\n",
    "model = CoronaVirusPredictor(\n",
    "  n_features=1, \n",
    "  n_hidden=512, \n",
    "  seq_len=seq_length, \n",
    "  n_layers=2\n",
    ")\n",
    "model, train_hist, _ = train_model(model, X_all, y_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Uw4JkktB9ceM"
   },
   "source": [
    "## Predicting future cases\n",
    "\n",
    "We'll use our \"fully trained\" model to predict the confirmed cases for 12 days into the future:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JBEHtvM9HbCi"
   },
   "outputs": [],
   "source": [
    "DAYS_TO_PREDICT = 12\n",
    "\n",
    "with torch.no_grad():\n",
    "  test_seq = X_all[:1]\n",
    "  preds = []\n",
    "  for _ in range(DAYS_TO_PREDICT):\n",
    "    y_test_pred = model(test_seq)\n",
    "    pred = torch.flatten(y_test_pred).item()\n",
    "    preds.append(pred)\n",
    "    new_seq = test_seq.numpy().flatten()\n",
    "    new_seq = np.append(new_seq, [pred])\n",
    "    new_seq = new_seq[1:]\n",
    "    test_seq = torch.as_tensor(new_seq).view(1, seq_length, 1).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CPO4SgsFZqS7"
   },
   "source": [
    "As before, we'll inverse the scaler transformation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hq7oUHf7H8nU"
   },
   "outputs": [],
   "source": [
    "predicted_cases = scaler.inverse_transform(\n",
    "  np.expand_dims(preds, axis=0)\n",
    ").flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WEXs4wOPayG2"
   },
   "source": [
    "To create a cool chart with the historical and predicted cases, we need to extend the date index of our data frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "0Dz4tBTeEb7r",
    "outputId": "3c038c12-818c-4c6e-8230-af1be0e3ee52"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2020-03-02 00:00:00')"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_cases.index[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 597
    },
    "colab_type": "code",
    "id": "ZwQxZz3BDrlI",
    "outputId": "8c0855e1-0e60-4015-a54f-1d340c8f6e70"
   },
   "outputs": [],
   "source": [
    "predicted_index = pd.date_range(\n",
    "  start=daily_cases.index[-1],\n",
    "  periods=DAYS_TO_PREDICT + 1,\n",
    "  inclusive='right'\n",
    ")\n",
    "\n",
    "predicted_cases = pd.Series(\n",
    "  data=predicted_cases,\n",
    "  index=predicted_index\n",
    ")\n",
    "\n",
    "plt.plot(predicted_cases, label='Predicted Daily Cases')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qBK71BNma8ec"
   },
   "source": [
    "Now we can use all the data to plot the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 597
    },
    "colab_type": "code",
    "id": "XyBC8y5FFBVX",
    "outputId": "34719970-a190-4435-8ed9-c086bf6e5a29"
   },
   "outputs": [],
   "source": [
    "plt.plot(daily_cases, label='Historical Daily Cases')\n",
    "plt.plot(predicted_cases, label='Predicted Daily Cases')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p6IgK4dTbhQL"
   },
   "source": [
    "Our model thinks that things will level off. Note that the more you go into the future, the more you shouldn't trust your model predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tVUVqYlPbh63"
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "Well done! You learned how to use PyTorch to create a Recurrent Neural Network that works with Time Series data. The model performance is not that great, but this is expected, given the small amounts of data.\n",
    "\n",
    "- [Run the complete notebook in your browser (Google Colab)](https://colab.research.google.com/drive/1nQYJq1f7f4R0yeZOzQ9rBKgk00AfLoS0)\n",
    "- [Read the Getting Things Done with Pytorch book](https://github.com/curiousily/Getting-Things-Done-with-Pytorch)\n",
    "\n",
    "The problem of predicting daily Covid-19 cases is a hard one. We're amidst an outbreak, and there's more to be done. Hopefully, everything will be back to normal after some time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ycqlac8X-9q-"
   },
   "source": [
    "## References\n",
    "\n",
    "- [Sequence Models PyTorch Tutorial](https://pytorch.org/tutorials/beginner/nlp/sequence_models_tutorial.html)\n",
    "- [LSTM for time series prediction](https://towardsdatascience.com/lstm-for-time-series-prediction-de8aeb26f2ca)\n",
    "- [Time Series Prediction using LSTM with PyTorch in Python](https://stackabuse.com/time-series-prediction-using-lstm-with-pytorch-in-python/)\n",
    "- [Stateful LSTM in Keras](https://philipperemy.github.io/keras-stateful-lstm/)\n",
    "- [LSTMs for Time Series in PyTorch](https://www.jessicayung.com/lstms-for-time-series-in-pytorch/)\n",
    "- [Novel Coronavirus (COVID-19) Cases, provided by JHU CSSE](https://github.com/CSSEGISandData/COVID-19)\n",
    "- [covid-19-analysis](https://github.com/AaronWard/covid-19-analysis)\n",
    "- [How does Coronavirus compare to Ebola, SARS, etc?](https://www.youtube.com/watch?v=6dDD2tHWWnU)\n",
    "- [Worldometer COVID-19 Coronavirus Outbreak](https://www.worldometers.info/coronavirus/)\n",
    "- [How contagious is the Wuhan Coronavirus? (Ro)](https://www.worldometers.info/coronavirus/#repro)\n",
    "- [Systemic Risk of Pandemic via Novel Pathogens - Coronavirus: A Note](https://www.academia.edu/41743064/Systemic_Risk_of_Pandemic_via_Novel_Pathogens_-_Coronavirus_A_Note)\n",
    "- [Statistical Consequences of Fat Tails: Real World Preasymptotics, Epistemology, and Applications](https://www.researchers.one/article/2020-01-21)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "time-series-covid-19.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
